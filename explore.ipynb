{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config - imports, constants, and mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "output_dir = \"../output/\"\n",
    "\n",
    "\"\"\" \n",
    "The groupings below map specific data-based claimed types to larger \n",
    "groupings. For example: nIa, Ia, Ia*, and Ia-HV all map to Ia.\n",
    "Any new claimed types to be considered in the analysis need to be added \n",
    "here and mapped to a larger group, which also needs to be in cat_code\n",
    "\"\"\"\n",
    "groupings = {\n",
    "#     Ia\n",
    "    'nIa' : 'Ia',\n",
    "    'Ia' : 'Ia',\n",
    "    'Ia*' :'Ia',\n",
    "    'Ia-HV' :'Ia',\n",
    "#     'Ia-91T'\n",
    "    'Ia-91T' : 'Ia-91T',\n",
    "#     'Ia-91bg'\n",
    "    'Ia-91bg' : 'Ia-91bg',\n",
    "#     'Ib/Ic'\n",
    "    'IIb/Ib/Ic (Ca rich)' : 'Ib/Ic',\n",
    "    'Ib/Ic (Ca rich)' : 'Ib/Ic',\n",
    "    'Ib (Ca rich)' : 'Ib/Ic',\n",
    "#     'Ia CSM'\n",
    "    'Ia CSM' : 'Ia CSM',\n",
    "#     'Ia-02cx'\n",
    "    'Ia-02cx' : 'Ia-02cx',\n",
    "    'Iax[02cx-like]' : 'Ia-02cx',\n",
    "#     'II P'\n",
    "    'II P' : 'II P',\n",
    "    'II-p' : 'II P',\n",
    "    'II Pec' : 'II P',\n",
    "    'II P Pec' : 'II P',\n",
    "    'II?' : 'II P',\n",
    "    'II Pec?' : 'II P',\n",
    "    'IIP?' : 'II P',\n",
    "    'II' : 'II P',\n",
    "#     'IIn'\n",
    "    'IIn' : 'IIn',\n",
    "    'IIn Pec' : 'IIn',\n",
    "    'LBV to IIn' : 'IIn',\n",
    "    'IIn-pec/LBV' : 'IIn',\n",
    "    'IIn?' : 'IIn',\n",
    "#     'Ib'\n",
    "    'Ib' : 'Ib',\n",
    "    'Ibn' : 'Ib',\n",
    "#     'Ic'\n",
    "    'Ic' : 'Ic',\n",
    "    'Ic?' : 'Ic',\n",
    "    'Ic-lum?' : 'Ic',\n",
    "    'Ic Pec' : 'Ic',\n",
    "#     Ic BL\n",
    "    'Ic BL' : 'Ic BL',\n",
    "    'BL-Ic' : 'Ic BL',\n",
    "#     'SLSN-II?'\n",
    "    'SLSN-II?' : 'SLSN-II?',\n",
    "#     'SLSN-I'\n",
    "    'SLSN-I' : 'SLSN-I',\n",
    "#     'LGRB'\n",
    "    'LGRB' : 'LGRB'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Claimed Type categories, mapped to integer values.\n",
    "The integer values are used by the ML model.\n",
    "\"\"\" \n",
    "cat_code = {\n",
    "    'LGRB': 1,\n",
    "    'Ia' : 2, \n",
    "    'II P': 3, \n",
    "    'Ib' : 4,\n",
    "    'Ic' : 5, \n",
    "    'IIn':6, \n",
    "    'SLSN-I' : 7, \n",
    "    'Ia-02cx' : 8,\n",
    "    'Ic BL' : 9, \n",
    "    'SLSN-II?': 10, \n",
    "    'Ia-91bg' : 11, \n",
    "    'Ia-91T' : 12, \n",
    "    'Ia CSM' : 13\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert .fits data to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(file = '../data/osc+otc-Assembled.fits'):\n",
    "    dat = Table.read(file, format='fits')\n",
    "    df_bytes = dat.to_pandas()  # Convert to pandas dataframe\n",
    "    df = pd.DataFrame()     # Init empty dataframe for converted types\n",
    "\n",
    "    # Convert byte columns to strings\n",
    "    for column in df_bytes:\n",
    "        if df_bytes[column].dtype == np.dtype('object'):\n",
    "            df[column + \"_str\"] = df_bytes[column].str.decode(\"utf-8\")\n",
    "            df[column] = df[column + \"_str\"].copy()\n",
    "            df.drop(column + \"_str\", axis = 1, inplace = True)\n",
    "        else:\n",
    "            df[column] = df_bytes[column]\n",
    "\n",
    "    # Prints sum of NULL values by column\n",
    "    df.isnull().sum().to_csv(output_dir + \"Missing_Values.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Group by Claimed Type and Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_cts(valid_df):\n",
    "    # Group claimed types into supergroups, defined in groupings dict\n",
    "    valid_df['claimedtype_group'] = valid_df.apply(lambda row:  \n",
    "                                             groupings[row.claimedtype] \n",
    "                                             if row.claimedtype in groupings \n",
    "                                             else None,\n",
    "                                             axis=1)\n",
    "\n",
    "    # Dataframe of claimed types that do not have group\n",
    "    ungrouped_types = list(set(valid_df.claimedtype.unique()) - set(groupings.keys()))\n",
    "    print(str(len(ungrouped_types)) + \" rows with ungrouped claimed type.\")\n",
    "\n",
    "    # Claimed Types that need to be grouped\n",
    "    add_cts = []\n",
    "    for ct in list(valid_df.claimedtype.unique()):\n",
    "        if \",\" not in ct and ct != '' and ct not in groupings:\n",
    "            add_cts.append(ct)\n",
    "    # Drop rows with no grouped claimed type      \n",
    "    valid_df = valid_df[~valid_df['claimedtype_group'].isnull()]\n",
    "    print (\"Remaining rows in valid dataframe: \" + str(valid_df.shape[0]))\n",
    "    \n",
    "    return valid_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up source and target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Target dataframe\n",
    "def set_up_target(df_rs_band):\n",
    "    df_analyze = df_rs_band.copy()\n",
    "\n",
    "    # Split out claimedtype_group into new dataframe\n",
    "    y = df_analyze.claimedtype_group.to_frame(name='group')\n",
    "    # Use category code numbers from cat_code dict, instead of strings\n",
    "    y['cat_code'] = y.apply(lambda row:  cat_code[row.group] , axis=1)\n",
    "    y = y.drop('group', axis = 1)\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "def set_up_source(df_analyze):\n",
    "    X = df_analyze.copy()\n",
    "    # Drop target column, and columns related to redshift or \n",
    "    # specific galactic identity (like ra and dec)\n",
    "    \n",
    "#     cols_to_drop = [\n",
    "#     #             Target\n",
    "#                 'claimedtype_group', \n",
    "#                 'claimedtype',\n",
    "\n",
    "#     #             Galactic info\n",
    "#                 'dec',\n",
    "#                 'ra',\n",
    "#                 'hostra',\n",
    "#                 'hostdec',\n",
    "#                 'hostoffsetang',\n",
    "#                 'hostoffsetdist',\n",
    "#                 'maxdate',\n",
    "#                 'hostoffsetdist',\n",
    "#                 'name', \n",
    "#                 'host',\n",
    "#                 'alias',\n",
    "#                 'NED_identifier', \n",
    "#                 'NED_flags',\n",
    "#                 'NED_searched',\n",
    "#                 'discoverdate',\n",
    "#                 'hostoffsetang',\n",
    "#                 'hostdec',\n",
    "        \n",
    "#                 'HyperLEDA_objname',\n",
    "#                 'HyperLEDA_f_astrom',\n",
    "#                 'HyperLEDA_pgc',\n",
    "        \n",
    "#                 'ebv',\n",
    "#                 'velocity',\n",
    "#                 'SDSS_MJD',\n",
    "#                 'SDSS_Plate',\n",
    "#                 'SDSS_FiberID',\n",
    "        \n",
    "\n",
    "#     #             Redshift info\n",
    "#                 'redshift',    \n",
    "#                 'lumdist', \n",
    "#                 'maxabsmag', \n",
    "#                 'maxappmag'\n",
    "#                 ]\n",
    "\n",
    "    X = X.drop(['redshift', 'claimedtype_group'], axis = 1)\n",
    "    \n",
    "    \n",
    "    # Encode all letters as numbers\n",
    "    le = LabelEncoder()\n",
    "    encoded_series = X[X.columns[:]].apply(le.fit_transform)\n",
    "    X = encoded_series\n",
    "    \n",
    "    return X\n",
    "\n",
    "def split_train_test(X, y):\n",
    "    # Split Training and Testing Data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=2)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_rm(X_train, X_test, y_train, y_test):\n",
    "    clf = RandomForestClassifier(max_depth = 8, random_state = 0, class_weight = \"balanced\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    return clf, predictions\n",
    "\n",
    "def get_performance(y_test, predictions):\n",
    "    return classification_report(y_test, predictions)\n",
    "\n",
    "def get_feature_importance(clf, X_train):\n",
    "    feature_importances = pd.DataFrame(clf.feature_importances_,\n",
    "                                       index = X_train.columns,\n",
    "                                       columns=['importance'])\n",
    "    feature_importances = feature_importances.sort_values('importance', \n",
    "                                                          ascending = False)\n",
    "    return feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(data_df, col_list, min_redshift, max_redshift):\n",
    "#     Collect and prep data\n",
    "    grouped_df = group_cts(data_df)\n",
    "    valid_df = grouped_df.copy()\n",
    "    \n",
    "#     Filter on specific list of columns to consider\n",
    "    col_list = col_list + ['redshift', 'claimedtype_group']\n",
    "    valid_df = valid_df[col_list]\n",
    "    \n",
    "#     Filter on specific redshift bin\n",
    "    valid_df = valid_df[(valid_df.redshift != 'nan') &\n",
    "                    (valid_df.redshift.str.contains(',') == False)]\n",
    "\n",
    "    valid_df['redshift'] = valid_df['redshift'].apply(pd.to_numeric)\n",
    "\n",
    "    df_rs_band = valid_df.loc[(valid_df.redshift > min_redshift) \n",
    "                        & (valid_df.redshift <= max_redshift)]\n",
    "    print(str(df_rs_band.shape[0]) + \" rows in redshift band: \" + str(min_redshift) + \" - \" + str(max_redshift))\n",
    "\n",
    "#     Run through ML\n",
    "    y = set_up_target(df_rs_band)\n",
    "    X = set_up_source(df_rs_band)\n",
    "    X_train, X_test, y_train, y_test = split_train_test(X, y)\n",
    "\n",
    "    clf, predictions = run_rm(X_train, X_test, y_train, y_test)\n",
    "    get_feature_importance(clf, X_train)\n",
    "    print(classification_report(y_test, predictions))\n",
    "    return clf, X_train, y_test, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the entire analysis using the cells below. Uses a sample of the original data with redshift within min_redshift and max_redshift, and using only fields in the col_list of the analysis. \n",
    "\n",
    "col_list - the list of data fields to use in the machine learning algorithm. They have been subdivided into spectral columns (available in the cell below). The reason for this is to consider only the spectra in the analysis. Considering any other fields leads to a higher risk of having a biased algorithm favoring redshift-driven characteristics. \n",
    "\n",
    "min_redshift - The minimum redshift to consider for the data sample, exclusive\n",
    "\n",
    "max_redshift - The maximum redshift to consider for the data sample, inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = collect_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, X_train, y_test, predictions = run_analysis(data_df = data_df,\n",
    "                            col_list = ned_sdss_cols,  \n",
    "                            min_redshift = 0.2, \n",
    "                            max_redshift = 0.3)\n",
    "get_feature_importance(clf, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_over_all_redshifts(sel_cols, valid_data):\n",
    "    for col_name in sel_cols:\n",
    "        valid_data = valid_data[valid_data[col_name].notnull()]\n",
    "\n",
    "    rs_mins = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "    rows = []\n",
    "    for rs_min in rs_mins:\n",
    "        rs_max = rs_min + 0.1\n",
    "        clf, X_train, y_test, predictions = run_analysis(data_df = data_df,\n",
    "                                col_list = sel_cols,  \n",
    "                                min_redshift = rs_min, \n",
    "                                max_redshift = rs_max)\n",
    "\n",
    "        df = get_feature_importance(clf, X_train)\n",
    "        col_vals = []\n",
    "        for col_name in sel_cols:\n",
    "            col_vals.append(df[df.index == col_name].importance[0])\n",
    "\n",
    "        types = list(range(1,14)) # list types to return, 1 to 13\n",
    "        recalls = list(recall_score(y_test, predictions, labels = types, average = None)) \n",
    "        ps = list(precision_score(y_test, predictions, labels = types, average = None)) \n",
    "        f1 = list(f1_score(y_test, predictions, labels = types, average = None))\n",
    "        class_2_recall = recalls[1]\n",
    "        class_3_recall = recalls[2]\n",
    "        class_2_ps = ps[1] \n",
    "        class_3_ps = ps[2]    \n",
    "        class_2_f1 = f1[1]\n",
    "        class_3_f1 = f1[2]\n",
    "        row = [rs_min, rs_max] + col_vals + [class_2_recall, class_3_recall, class_2_ps, class_3_ps, class_2_f1, class_3_f1]\n",
    "        rows.append(row)\n",
    "        \n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "ned_mass_cols = ['NED_2MASS_J', 'NED_2MASS_H', 'NED_2MASS_Ks']\n",
    "\n",
    "ned_sdss_cols = ['NED_SDSS_u', 'NED_SDSS_g', 'NED_SDSS_r', 'NED_SDSS_i', 'NED_SDSS_z']\n",
    "\n",
    "ned_galex_cols = ['NED_GALEX_NUV', 'NED_GALEX_FUV']\n",
    "\n",
    "ned_iras_cols = ['NED_IRAS_12m', 'NED_IRAS_25m', 'NED_IRAS_60m', 'NED_IRAS_100m', 'NED_HI_21cm', 'NED_1p4GHz']\n",
    "\n",
    "allwise_cols = ['AllWISE_W1', 'AllWISE_W2', 'AllWISE_W3', 'AllWISE_W4']\n",
    "\n",
    "firefly_cols = ['Firefly_Chabrier_MILES_Age_LW',\n",
    " 'Firefly_Chabrier_MILES_Metallicity_LW',\n",
    " 'Firefly_Chabrier_MILES_logMstar',\n",
    " 'Firefly_Chabrier_MILES_nSSP',\n",
    " 'Firefly_Chabrier_MILES_spm_EBV']\n",
    "\n",
    "mpa_cols = [col for col in list(data_df) if \"MPAJHU\" in col] # MPAJHU\n",
    "# HyperLEDA\n",
    "\n",
    "# GalaxyZoo\n",
    "zoo_cols = [col for col in list(data_df) if \"Zoo\" in col] # MPAJHU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MPAJHU_ARIII7135_Eqw',\n",
       " 'MPAJHU_ARIII7135_Eqw_Err',\n",
       " 'MPAJHU_HEI_5876_Eqw',\n",
       " 'MPAJHU_HEI_5876_Eqw_Err',\n",
       " 'MPAJHU_H_ALPHA_Eqw',\n",
       " 'MPAJHU_H_ALPHA_Eqw_Err',\n",
       " 'MPAJHU_H_BETA_Eqw',\n",
       " 'MPAJHU_H_BETA_Eqw_Err',\n",
       " 'MPAJHU_H_DELTA_Eqw',\n",
       " 'MPAJHU_H_DELTA_Eqw_Err',\n",
       " 'MPAJHU_H_GAMMA_Eqw',\n",
       " 'MPAJHU_H_GAMMA_Eqw_Err',\n",
       " 'MPAJHU_NEIII_3869_Eqw',\n",
       " 'MPAJHU_NEIII_3869_Eqw_Err',\n",
       " 'MPAJHU_NII_6548_Eqw',\n",
       " 'MPAJHU_NII_6548_Eqw_Err',\n",
       " 'MPAJHU_NII_6584_Eqw',\n",
       " 'MPAJHU_NII_6584_Eqw_Err',\n",
       " 'MPAJHU_OIII_4363_Eqw',\n",
       " 'MPAJHU_OIII_4363_Eqw_Err',\n",
       " 'MPAJHU_OIII_4959_Eqw',\n",
       " 'MPAJHU_OIII_4959_Eqw_Err',\n",
       " 'MPAJHU_OIII_5007_Eqw',\n",
       " 'MPAJHU_OIII_5007_Eqw_Err',\n",
       " 'MPAJHU_OII_3726_Eqw',\n",
       " 'MPAJHU_OII_3726_Eqw_Err',\n",
       " 'MPAJHU_OII_3729_Eqw',\n",
       " 'MPAJHU_OII_3729_Eqw_Err',\n",
       " 'MPAJHU_OI_6300_Eqw',\n",
       " 'MPAJHU_OI_6300_Eqw_Err',\n",
       " 'MPAJHU_SII_6717_Eqw',\n",
       " 'MPAJHU_SII_6717_Eqw_Err',\n",
       " 'MPAJHU_ARIII7135_Flux',\n",
       " 'MPAJHU_ARIII7135_Flux_Err',\n",
       " 'MPAJHU_HEI_5876_Flux',\n",
       " 'MPAJHU_HEI_5876_Flux_Err',\n",
       " 'MPAJHU_H_ALPHA_Flux',\n",
       " 'MPAJHU_H_ALPHA_Flux_Err',\n",
       " 'MPAJHU_H_BETA_Flux',\n",
       " 'MPAJHU_H_BETA_Flux_Err',\n",
       " 'MPAJHU_H_DELTA_Flux',\n",
       " 'MPAJHU_H_DELTA_Flux_Err',\n",
       " 'MPAJHU_H_GAMMA_Flux',\n",
       " 'MPAJHU_H_GAMMA_Flux_Err',\n",
       " 'MPAJHU_NEIII_3869_Flux',\n",
       " 'MPAJHU_NEIII_3869_Flux_Err',\n",
       " 'MPAJHU_NII_6548_Flux',\n",
       " 'MPAJHU_NII_6548_Flux_Err',\n",
       " 'MPAJHU_NII_6584_Flux',\n",
       " 'MPAJHU_NII_6584_Flux_Err',\n",
       " 'MPAJHU_OIII_4363_Flux',\n",
       " 'MPAJHU_OIII_4363_Flux_Err',\n",
       " 'MPAJHU_OIII_4959_Flux',\n",
       " 'MPAJHU_OIII_4959_Flux_Err',\n",
       " 'MPAJHU_OIII_5007_Flux',\n",
       " 'MPAJHU_OIII_5007_Flux_Err',\n",
       " 'MPAJHU_OII_3726_Flux',\n",
       " 'MPAJHU_OII_3726_Flux_Err',\n",
       " 'MPAJHU_OII_3729_Flux',\n",
       " 'MPAJHU_OII_3729_Flux_Err',\n",
       " 'MPAJHU_OI_6300_Flux',\n",
       " 'MPAJHU_OI_6300_Flux_Err',\n",
       " 'MPAJHU_SII_6717_Flux',\n",
       " 'MPAJHU_SII_6717_Flux_Err',\n",
       " 'MPAJHU_Idx_BH_CAI',\n",
       " 'MPAJHU_Idx_BH_CAI_Err',\n",
       " 'MPAJHU_Idx_BH_CNB',\n",
       " 'MPAJHU_Idx_BH_CNB_Err',\n",
       " 'MPAJHU_Idx_BH_FC',\n",
       " 'MPAJHU_Idx_BH_FC_Err',\n",
       " 'MPAJHU_Idx_BH_G',\n",
       " 'MPAJHU_Idx_BH_G_Err',\n",
       " 'MPAJHU_Idx_BH_HB',\n",
       " 'MPAJHU_Idx_BH_HB_Err',\n",
       " 'MPAJHU_Idx_BH_HK',\n",
       " 'MPAJHU_Idx_BH_HK_Err',\n",
       " 'MPAJHU_Idx_BH_MGG',\n",
       " 'MPAJHU_Idx_BH_MGG_Err',\n",
       " 'MPAJHU_Idx_BH_MH',\n",
       " 'MPAJHU_Idx_BH_MH_Err',\n",
       " 'MPAJHU_Idx_BH_NAD',\n",
       " 'MPAJHU_Idx_BH_NAD_Err',\n",
       " 'MPAJHU_Idx_D4000',\n",
       " 'MPAJHU_Idx_D4000_Err',\n",
       " 'MPAJHU_Idx_D4000_N',\n",
       " 'MPAJHU_Idx_D4000_N_Err',\n",
       " 'MPAJHU_Idx_DTT_CAII8498',\n",
       " 'MPAJHU_Idx_DTT_CAII8498_Err',\n",
       " 'MPAJHU_Idx_DTT_CAII8542',\n",
       " 'MPAJHU_Idx_DTT_CAII8542_Err',\n",
       " 'MPAJHU_Idx_DTT_CAII8662',\n",
       " 'MPAJHU_Idx_DTT_CAII8662_Err',\n",
       " 'MPAJHU_Idx_DTT_MGI8807',\n",
       " 'MPAJHU_Idx_DTT_MGI8807_Err',\n",
       " 'MPAJHU_Idx_LICK_C4668',\n",
       " 'MPAJHU_Idx_LICK_C4668_Err',\n",
       " 'MPAJHU_Idx_LICK_CA4227',\n",
       " 'MPAJHU_Idx_LICK_CA4227_Err',\n",
       " 'MPAJHU_Idx_LICK_CA4455',\n",
       " 'MPAJHU_Idx_LICK_CA4455_Err',\n",
       " 'MPAJHU_Idx_LICK_CN1',\n",
       " 'MPAJHU_Idx_LICK_CN1_Err',\n",
       " 'MPAJHU_Idx_LICK_CN2',\n",
       " 'MPAJHU_Idx_LICK_CN2_Err',\n",
       " 'MPAJHU_Idx_LICK_FE4383',\n",
       " 'MPAJHU_Idx_LICK_FE4383_Err',\n",
       " 'MPAJHU_Idx_LICK_FE4531',\n",
       " 'MPAJHU_Idx_LICK_FE4531_Err',\n",
       " 'MPAJHU_Idx_LICK_FE5015',\n",
       " 'MPAJHU_Idx_LICK_FE5015_Err',\n",
       " 'MPAJHU_Idx_LICK_FE5270',\n",
       " 'MPAJHU_Idx_LICK_FE5270_Err',\n",
       " 'MPAJHU_Idx_LICK_FE5335',\n",
       " 'MPAJHU_Idx_LICK_FE5335_Err',\n",
       " 'MPAJHU_Idx_LICK_FE5406',\n",
       " 'MPAJHU_Idx_LICK_FE5406_Err',\n",
       " 'MPAJHU_Idx_LICK_FE5709',\n",
       " 'MPAJHU_Idx_LICK_FE5709_Err',\n",
       " 'MPAJHU_Idx_LICK_FE5782',\n",
       " 'MPAJHU_Idx_LICK_FE5782_Err',\n",
       " 'MPAJHU_Idx_LICK_G4300',\n",
       " 'MPAJHU_Idx_LICK_G4300_Err',\n",
       " 'MPAJHU_Idx_LICK_HB',\n",
       " 'MPAJHU_Idx_LICK_HB_Err',\n",
       " 'MPAJHU_Idx_LICK_HD_A',\n",
       " 'MPAJHU_Idx_LICK_HD_A_Err',\n",
       " 'MPAJHU_Idx_LICK_HD_F',\n",
       " 'MPAJHU_Idx_LICK_HD_F_Err',\n",
       " 'MPAJHU_Idx_LICK_HG_A',\n",
       " 'MPAJHU_Idx_LICK_HG_A_Err',\n",
       " 'MPAJHU_Idx_LICK_HG_F',\n",
       " 'MPAJHU_Idx_LICK_HG_F_Err',\n",
       " 'MPAJHU_Idx_LICK_MG1',\n",
       " 'MPAJHU_Idx_LICK_MG1_Err',\n",
       " 'MPAJHU_Idx_LICK_MG2',\n",
       " 'MPAJHU_Idx_LICK_MG2_Err',\n",
       " 'MPAJHU_Idx_LICK_MGB',\n",
       " 'MPAJHU_Idx_LICK_MGB_Err',\n",
       " 'MPAJHU_Idx_LICK_NAD',\n",
       " 'MPAJHU_Idx_LICK_NAD_Err',\n",
       " 'MPAJHU_Idx_LICK_TIO1',\n",
       " 'MPAJHU_Idx_LICK_TIO1_Err',\n",
       " 'MPAJHU_Idx_LICK_TIO2',\n",
       " 'MPAJHU_Idx_LICK_TIO2_Err',\n",
       " 'MPAJHU_Idx_TAUV_CONT',\n",
       " 'MPAJHU_Idx_TAUV_CONT_Err',\n",
       " 'MPAJHU_logMstar',\n",
       " 'MPAJHU_logMstar_Err',\n",
       " 'MPAJHU_logMstar_fib',\n",
       " 'MPAJHU_logMstar_fib_Err',\n",
       " 'MPAJHU_logSFR',\n",
       " 'MPAJHU_logSFR_Err',\n",
       " 'MPAJHU_logSFR_fib',\n",
       " 'MPAJHU_logSFR_fib_Err',\n",
       " 'MPAJHU_logSpecSFR',\n",
       " 'MPAJHU_logSpecSFR_Err',\n",
       " 'MPAJHU_logSpecSFR_fib',\n",
       " 'MPAJHU_logSpecSFR_fib_Err',\n",
       " 'MPAJHU_OH',\n",
       " 'MPAJHU_OH_Err',\n",
       " 'MPAJHU_BPTClass']"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpa_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "391 rows with ungrouped claimed type.\n",
      "Remaining rows in valid dataframe: 15959\n",
      "4230 rows in redshift band: 0 - 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.74      0.43      0.54       911\n",
      "          3       0.33      0.39      0.36       351\n",
      "          4       0.00      0.00      0.00        33\n",
      "          5       0.07      0.22      0.11        55\n",
      "          6       0.04      0.22      0.07        37\n",
      "          9       0.00      0.00      0.00         4\n",
      "         11       0.00      0.00      0.00         2\n",
      "         12       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.57      0.39      0.45      1396\n",
      "\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marina/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391 rows with ungrouped claimed type.\n",
      "Remaining rows in valid dataframe: 15959\n",
      "1272 rows in redshift band: 0.1 - 0.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         1\n",
      "          2       0.91      0.80      0.85       335\n",
      "          3       0.47      0.75      0.58        71\n",
      "          4       0.00      0.00      0.00         1\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "         12       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.81      0.77      0.78       420\n",
      "\n",
      "0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marina/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391 rows with ungrouped claimed type.\n",
      "Remaining rows in valid dataframe: 15959\n",
      "691 rows in redshift band: 0.2 - 0.30000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.25      1.00      0.40         1\n",
      "          2       0.81      0.76      0.79       176\n",
      "          3       0.30      0.38      0.34        45\n",
      "          5       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         2\n",
      "          7       0.00      0.00      0.00         4\n",
      "         13       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.68      0.66      0.67       229\n",
      "\n",
      "0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marina/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391 rows with ungrouped claimed type.\n",
      "Remaining rows in valid dataframe: 15959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marina/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589 rows in redshift band: 0.3 - 0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.50      0.67         2\n",
      "          2       0.90      0.87      0.89       175\n",
      "          3       0.09      0.12      0.10        16\n",
      "          4       0.00      0.00      0.00         1\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.83      0.80      0.81       195\n",
      "\n",
      "0.4\n",
      "391 rows with ungrouped claimed type.\n",
      "Remaining rows in valid dataframe: 15959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marina/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265 rows in redshift band: 0.4 - 0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       0.86      0.94      0.90        72\n",
      "          3       0.43      0.23      0.30        13\n",
      "          7       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.79      0.83      0.80        88\n",
      "\n",
      "0.5\n",
      "391 rows with ungrouped claimed type.\n",
      "Remaining rows in valid dataframe: 15959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marina/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 rows in redshift band: 0.5 - 0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.67      0.57         3\n",
      "          2       0.83      0.83      0.83        41\n",
      "          3       0.17      0.20      0.18         5\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.71      0.73      0.72        51\n",
      "\n",
      "0.6\n",
      "391 rows with ungrouped claimed type.\n",
      "Remaining rows in valid dataframe: 15959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marina/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 rows in redshift band: 0.6 - 0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.25      0.40         4\n",
      "          2       0.74      0.88      0.80        16\n",
      "          3       0.25      0.33      0.29         3\n",
      "          7       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.69      0.67      0.64        24\n",
      "\n",
      "0.7\n",
      "391 rows with ungrouped claimed type.\n",
      "Remaining rows in valid dataframe: 15959\n",
      "53 rows in redshift band: 0.7 - 0.7999999999999999\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.33      0.67      0.44         3\n",
      "          2       0.83      0.77      0.80        13\n",
      "          3       0.00      0.00      0.00         1\n",
      "          7       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.66      0.67      0.65        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marina/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marina/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "cur_cols = zoo_cols\n",
    "rows = run_over_all_redshifts(cur_cols, data_df.copy())\n",
    "report = pd.DataFrame(rows, columns = ['min redshift', 'max redshift'] + cur_cols + ['Ia Recall',  'II P Recall', 'Ia Precision', 'II P Precision', 'Ia F1', 'II P F1'])\n",
    "report.round(decimals = 2).to_csv(\"../output/performance/zoo_cols.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Profiling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Feature Distribution by Claimed Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distribution of features across claimed type group\n",
    "type_counts = pd.crosstab(df_rs_band['claimedtype_group'], \n",
    "                                    columns = [df_rs_band['masses'],\n",
    "                                              df_rs_band['velocity'],\n",
    "                                              df_rs_band['SDSS_SpecMatched'],\n",
    "                                              df_rs_band['SDSS_FiberID'],\n",
    "                                              df_rs_band['SDSS_MJD'],\n",
    "                                              df_rs_band['SDSS_Plate'],\n",
    "                                              df_rs_band['MPAJHU_BPTClass'],\n",
    "                                              df_rs_band['WiscPCA_src'],\n",
    "                                              df_rs_band['HyperLEDA_type'],\n",
    "                                              df_rs_band['HyperLEDA_bar'],\n",
    "                                              df_rs_band['HyperLEDA_ring'],\n",
    "                                               df_rs_band['HyperLEDA_multiple'],\n",
    "                                               df_rs_band['HyperLEDA_compactness'],\n",
    "                                               df_rs_band['HyperLEDA_agnclass']\n",
    "                                                ])\n",
    "type_counts.to_csv(\"feature_counts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of the number of claimed types within each range of redshifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group redshifts into bins of .5\n",
    "bin_size = 0.1\n",
    "range_bins = list(np.arange(int(rsmin)-1, int(rsmax) + 2, bin_size))\n",
    "\n",
    "# Create aggregate frame based on redshift and claimedtype_group\n",
    "df_agg = valid_df.copy()\n",
    "df_agg = df_agg[['claimedtype_group','redshift']]\n",
    "# Split counts into bins of redshift, of bin_size\n",
    "df_agg['rs_range'] = pd.cut(df_agg['redshift'], bins = range_bins)\n",
    "\n",
    "# Flip axis so each bin is a column\n",
    "grouping = df_agg.groupby(['claimedtype_group',\n",
    "                           'rs_range']).size().reset_index(name = 'counts')\n",
    "g = pd.DataFrame(grouping)\n",
    "col_headers = [df_agg.rs_range.unique()]\n",
    "ct_range = g.pivot(index = 'claimedtype_group', columns = 'rs_range')['counts']\n",
    "\n",
    "# Save claimedtype ranges to CSV\n",
    "ct_range.to_csv(output_dir + \"ct_range_bin_\" + str(bin_size) + \".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
